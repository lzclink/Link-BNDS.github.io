<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"link-bnds.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.7.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="1. 前言在Coursera上吴恩达的Machine Learning中，Logistic Regression作为初学者们接触到的第二个模型，其本身是非常重要的。但是在课程当中其损失函数的梯度公式则被一笔带过。而很多人都对其为什么与线性回归的损失函数梯度是一样的表示好奇，因此，我特地从头推导了这一式子。 2. 逻辑斯蒂回归损失函数梯度推导2.1. IntroductionThe “Machine">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic_Regression">
<meta property="og:url" content="https://link-bnds.github.io/Logistic-Regression/index.html">
<meta property="og:site_name" content="Link LZCのBlog">
<meta property="og:description" content="1. 前言在Coursera上吴恩达的Machine Learning中，Logistic Regression作为初学者们接触到的第二个模型，其本身是非常重要的。但是在课程当中其损失函数的梯度公式则被一笔带过。而很多人都对其为什么与线性回归的损失函数梯度是一样的表示好奇，因此，我特地从头推导了这一式子。 2. 逻辑斯蒂回归损失函数梯度推导2.1. IntroductionThe “Machine">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-07-28T15:28:23.000Z">
<meta property="article:modified_time" content="2022-07-28T15:44:51.433Z">
<meta property="article:author" content="Link LZC">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://link-bnds.github.io/Logistic-Regression/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://link-bnds.github.io/Logistic-Regression/","path":"Logistic-Regression/","title":"Logistic_Regression"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Logistic_Regression | Link LZCのBlog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Link LZCのBlog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Accumulation</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-schedule"><a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E5%89%8D%E8%A8%80"><span class="nav-number">1.</span> <span class="nav-text">1. 前言</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E9%80%BB%E8%BE%91%E6%96%AF%E8%92%82%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%A2%AF%E5%BA%A6%E6%8E%A8%E5%AF%BC"><span class="nav-number">2.</span> <span class="nav-text">2. 逻辑斯蒂回归损失函数梯度推导</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Introduction"><span class="nav-number">2.1.</span> <span class="nav-text">2.1. Introduction</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Logistic-Regression"><span class="nav-number">2.2.</span> <span class="nav-text">2.2. Logistic Regression</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-Cost-Function"><span class="nav-number">2.3.</span> <span class="nav-text">2.3. Cost Function</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-Gradient-of-Cost-Function"><span class="nav-number">2.4.</span> <span class="nav-text">2.4. Gradient of Cost Function</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Link LZC"
      src="/images/rin.png">
  <p class="site-author-name" itemprop="name">Link LZC</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">69</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Link-BNDS" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Link-BNDS" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://space.bilibili.com/31118078" title="Bilibili → https:&#x2F;&#x2F;space.bilibili.com&#x2F;31118078" rel="noopener" target="_blank">Bilibili</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:kpl12345yh@163.com" title="E-Mail → mailto:kpl12345yh@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



          </div>
        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="Back to top">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://link-bnds.github.io/Logistic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/rin.png">
      <meta itemprop="name" content="Link LZC">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Link LZCのBlog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Logistic_Regression
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-07-28 23:28:23 / Modified: 23:44:51" itemprop="dateCreated datePublished" datetime="2022-07-28T23:28:23+08:00">2022-07-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h3><p>在Coursera上吴恩达的Machine Learning中，Logistic Regression作为初学者们接触到的第二个模型，其本身是非常重要的。但是在课程当中其损失函数的梯度公式则被一笔带过。而很多人都对其为什么与线性回归的损失函数梯度是一样的表示好奇，因此，我特地从头推导了这一式子。</p>
<h3 id="2-逻辑斯蒂回归损失函数梯度推导"><a href="#2-逻辑斯蒂回归损失函数梯度推导" class="headerlink" title="2. 逻辑斯蒂回归损失函数梯度推导"></a>2. 逻辑斯蒂回归损失函数梯度推导</h3><h4 id="2-1-Introduction"><a href="#2-1-Introduction" class="headerlink" title="2.1. Introduction"></a>2.1. Introduction</h4><p>The “Machine Learning” course on Coursera is a one of the most popular course over all of MOOC. This course is famous for its simplified teaching step and other bright spots. Logistics regression, as the most important model for beginner, lacks appropriate detailed derivation of formula. In this blog, I am going to expound this section step by step.</p>
<h4 id="2-2-Logistic-Regression"><a href="#2-2-Logistic-Regression" class="headerlink" title="2.2. Logistic Regression"></a>2.2. Logistic Regression</h4><p>I think most of you have already got familiar with logistic regression.</p>
<h4 id="2-3-Cost-Function"><a href="#2-3-Cost-Function" class="headerlink" title="2.3. Cost Function"></a>2.3. Cost Function</h4><p>As we all know, the cost function of the logistic regression is modified from the one from linear regression model.</p>
<script type="math/tex; mode=display">
Cost\left( h_{\theta}\left( x \right) ,y \right) =\left\{ \begin{aligned}
    -\log \left( h_{\theta}\left( x \right) \right) \,\,   if\,\,y&=1\\
    -\log \left( 1-h_{\theta}\left( x \right) \right) \,\, if\,\,y&=0\\
\end{aligned} \right.</script><p>To simplify this function, we can write it as</p>
<script type="math/tex; mode=display">
J\left( \theta \right) =\frac{1}{2m}\sum_{i=1}^m{Cost\left( h_{\theta}\left( x^{\left( i \right)} \right) ,y^{\left( i \right)} \right)}</script><p>which</p>
<script type="math/tex; mode=display">
Cost\left( h_{\theta}\left( x^{\left( i \right)} \right) ,y^{\left( i \right)} \right) =-y^{\left( i \right)}\log \left( h_{\theta}\left( x \right) \right) -\left( 1-y^{\left( i \right)} \right) \log \left( 1-h_{\theta}\left( x^{\left( i \right)} \right) \right)</script><h4 id="2-4-Gradient-of-Cost-Function"><a href="#2-4-Gradient-of-Cost-Function" class="headerlink" title="2.4. Gradient of Cost Function"></a>2.4. Gradient of Cost Function</h4><p>And next, is the part I want to expound. Andrew, in this MOOC, just briefly introduce that the gradient of the new cost function is the same as the one for linear regression. There is no explicit derivation here. </p>
<p>For cost function $J$, we can write it as</p>
<p>\begin{equation}<br>\begin{aligned}<br>J\left( \theta \right) &amp;=-\frac{1}{m}\left[ \sum<em>{i=1}^m{-y^{\left( i \right)}\log \left( h</em>{\theta}\left( x \right) \right) -\left( 1-y^{\left( i \right)} \right) \log \left( 1-h<em>{\theta}\left( x^{\left( i \right)} \right) \right)} \right]<br>\<br>\frac{\partial}{\partial \theta _j}J\left( \theta \right) &amp;=\frac{\partial}{\partial \theta _j}\left[ -\frac{1}{m}\left[ \sum</em>{i=1}^m{-y^{\left( i \right)}\log \left( h<em>{\theta}\left( x \right) \right) -\left( 1-y^{\left( i \right)} \right) \log \left( 1-h</em>{\theta}\left( x^{\left( i \right)} \right) \right)} \right] \right]<br>\<br>&amp;=-\frac{1}{m}\left[ \sum<em>{i=1}^m{\left( y^{\left( i \right)}\frac{1}{h</em>{\theta}\left( x^{\left( i \right)} \right)}\cdot \frac{\partial}{\partial \theta <em>j}h</em>{\theta}\left( x^{\left( i \right)} \right) +\left( 1-y^{\left( i \right)} \right) \cdot \frac{1}{1-h<em>{\theta}\left( x^{\left( i \right)} \right)}\cdot \frac{\partial}{\partial \theta _j}\left( -h</em>{\theta}\left( x^{\left( i \right)} \right) \right) \right)} \right]<br>\<br>&amp;=-\frac{1}{m}\left[ \sum<em>{i=1}^m{\left( y^{\left( i \right)}\frac{1}{h</em>{\theta}\left( x^{\left( i \right)} \right)}-\left( 1-y^{\left( i \right)} \right) \cdot \frac{1}{1-h<em>{\theta}\left( x^{\left( i \right)} \right)} \right) \cdot \frac{\partial}{\partial \theta _j}\left( h</em>{\theta}\left( x^{\left( i \right)} \right) \right)} \right]<br>\<br>&amp;=-\frac{1}{m}\left[ \sum_{i=1}^m{\left( y^{\left( i \right)}\frac{1}{g\left( \theta ^Tx \right)}-\left( 1-y^{\left( i \right)} \right) \cdot \frac{1}{1-g\left( \theta ^Tx \right)} \right) \cdot \frac{\partial}{\partial \theta _j}\left( g\left( \theta ^Tx \right) \right)} \right] </p>
<p>\end{aligned}<br>\end{equation}</p>
<p>In logistic regression, we use the logistic function as our decision function. Therefore, (Mentioned: $T$ refers to transpose)</p>
<p>\begin{equation}<br>    \begin{aligned}<br>\frac{\partial}{\partial \theta _j}g\left( \theta ^Tx \right) &amp;=\frac{\partial}{\partial \theta _j}\cdot \frac{1}{1+e^{-\theta ^Tx}}<br>\<br>&amp;=\frac{\partial}{\partial \theta _j}\left( 1+e^{-\theta ^Tx} \right) ^{-1}<br>\<br>&amp;=-\left( 1+e^{-\theta ^Tx} \right) ^{-2}\cdot e^{e^{-\theta ^Tx}}\cdot x<br>\<br>&amp;=-\frac{e^{e^{-\theta ^Tx}}\cdot -x}{\left( 1+e^{e^{-\theta ^Tx}} \right) ^2}<br>    \end{aligned}<br>\end{equation}</p>
<p>We set $k=e^{-\theta ^Tx}$, plug it in,</p>
<p>\begin{equation}<br>    \begin{aligned}<br>&amp;=\frac{k}{\left( 1+k \right) ^2}\cdot x<br>\<br>&amp;=\left( \frac{1}{1+k}\cdot \frac{1+k-1}{1+k} \right) \cdot x<br>\<br>&amp;=\left[ \frac{1}{1+k}\cdot \left( 1-\frac{1}{1+k} \right) \right] \cdot x<br>    \end{aligned}<br>\end{equation}</p>
<p>Bring it back, we can see we construct the logistic function itself,</p>
<p>\begin{equation}<br>    \begin{aligned}<br>    &amp;=\left[ \frac{1}{1+e^{-\theta ^Tx}}\cdot \left( 1-\frac{1}{1+e^{-\theta ^Tx}} \right) \right] \cdot x<br>    \end{aligned}<br>\end{equation}</p>
<p>Thus, we can use the logistic function to simplify the eqution,</p>
<p>\begin{equation}<br>    \begin{aligned}<br>&amp;=\left[ \frac{1}{1+e^{-\theta ^Tx}}\cdot \left( 1-\frac{1}{1+e^{-\theta ^Tx}} \right) \right] \cdot x<br>\<br>&amp;=g\left( \theta ^Tx \right) \cdot \left( 1-g\left( \theta ^Tx \right) \right) \cdot x<br>    \end{aligned}<br>\end{equation}</p>
<p>We plug back this portion to the gradient of cost function (1), </p>
<p>\begin{equation}<br>    \begin{aligned}<br>\frac{\partial}{\partial \theta <em>j}J\left( \theta \right) &amp;=-\frac{1}{m}\left[ \sum</em>{i=1}^m{\left( y^{\left( i \right)}\cdot \frac{1}{g\left( \theta ^Tx \right)}-\left( 1-y^{\left( i \right)} \right) \cdot \frac{1}{1-g\left( \theta ^Tx \right)} \right)}\cdot g\left( \theta ^Tx \right) \cdot \left( 1-g\left( \theta ^Tx \right) \right) \cdot x^{\left( i \right)} \right]<br>\<br>&amp;=-\frac{1}{m}\left[ \sum<em>{i=1}^m{\left[ y^{\left( i \right)}\cdot \left( 1-g\left( \theta ^Tx \right) \right) \cdot x^{\left( i \right)}-\left( 1-y^{\left( i \right)} \right) \cdot g\left( \theta ^Tx \right) \cdot x^{\left( i \right)} \right]} \right]<br>\<br>&amp;=-\frac{1}{m}\sum</em>{i=1}^m{\left[ y^{\left( i \right)}\cdot x^{\left( i \right)}-y^{\left( i \right)}\cdot g\left( \theta ^Tx \right) \cdot x^{\left( i \right)}-g\left( \theta ^Tx \right) \cdot x^{\left( i \right)}+y^{\left( i \right)}\cdot g\left( \theta ^Tx \right) \cdot x^{\left( i \right)} \right]}<br>\<br>&amp;\mathrm{because}-y^{\left( i \right)}\cdot g\left( \theta ^Tx \right) \cdot x^{\left( i \right)}\,\,\mathrm{offsets} +y^{\left( i \right)}\cdot g\left( \theta ^Tx \right) \cdot x^{\left( i \right)}<br>\<br>&amp;=-\frac{1}{m}\sum<em>{i=1}^m{\left[ y^{\left( i \right)}\cdot x^{\left( i \right)}-g\left( \theta ^Tx \right) \cdot x^{\left( i \right)} \right]}<br>\<br>&amp;=-\frac{1}{m}\sum</em>{i=1}^m{\left[ \left[ y^{\left( i \right)}-g\left( \theta ^Tx \right) \right] \cdot x^{\left( i \right)} \right]}<br>\<br>&amp;=\frac{1}{m}\sum<em>{i=1}^m{\left[ \left[ h</em>{\theta}\left( x^{\left( i \right)} \right) -y^{\left( i \right)} \right] \cdot x^{\left( i \right)} \right]}<br>  \end{aligned}<br>\end{equation}</p>
<p>which is the same as linear regression’s </p>
<p>Q.E.D.</p>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Link LZC
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://link-bnds.github.io/Logistic-Regression/" title="Logistic_Regression">https://link-bnds.github.io/Logistic-Regression/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/Stokes-Theorem/" rel="prev" title="Stokes_Theorem">
                  <i class="fa fa-chevron-left"></i> Stokes_Theorem
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/APCSA-Practice/" rel="next" title="APCSA_Practice">
                  APCSA_Practice <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Link LZC</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  




  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
